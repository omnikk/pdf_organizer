import os
import re
import shutil
import pandas as pd
from pathlib import Path
import easyocr
from pdf2image import convert_from_path
import cv2
import numpy as np
from datetime import datetime
from collections import Counter
import warnings
import time

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
warnings.filterwarnings("ignore")

class CertificateProcessorBalanced:
    def __init__(self):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
        import torch
        if torch.cuda.is_available():
            print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {torch.cuda.get_device_name(0)}")
            self.reader = easyocr.Reader(['ru'], gpu=True)
        else:
            print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)")
            self.reader = easyocr.Reader(['ru'], gpu=False)
            
        self.base_dir = Path.cwd()
        self.input_dir = self.base_dir / "input"
        self.certificates_dir = self.base_dir / "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã"
        self.debug_dir = self.base_dir / "debug"
        self.unknown_dir = self.certificates_dir / "–ù–µ–æ–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ"
        
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏
        self.create_directories()
        
        # –°–ø–∏—Å–æ–∫ –¥–ª—è CSV
        self.csv_data = []
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        self.timing_stats = []
        
    def create_directories(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
        for directory in [self.certificates_dir, self.debug_dir, self.unknown_dir]:
            directory.mkdir(exist_ok=True)
    
    def preprocess_image_enhanced(self, image):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        height, width = gray.shape
        gray = cv2.resize(gray, (width * 2, height * 2), interpolation=cv2.INTER_CUBIC)
        
        # –£–±–∏—Ä–∞–µ–º —à—É–º
        denoised = cv2.fastNlMeansDenoising(gray)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
        binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY, 11, 2)
        
        return binary
    
    def preprocess_image_simple(self, image):
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # –ü—Ä–æ—Å—Ç–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∏
        enhanced = cv2.convertScaleAbs(gray, alpha=1.5, beta=30)
        
        # –ì–∞—É—Å—Å–æ–≤–æ —Ä–∞–∑–º—ã—Ç–∏–µ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)
        
        return blurred
    
    def extract_text_from_pdf_balanced(self, pdf_path):
        """–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (2-3 –ø–æ–ø—ã—Ç–∫–∏)"""
        start_time = time.time()
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ö–æ—Ä–æ—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            images = convert_from_path(pdf_path, dpi=300)
            pdf_time = time.time() - start_time
            
            all_text = ""
            ocr_start = time.time()
            
            for image in images:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL –≤ opencv —Ñ–æ—Ä–º–∞—Ç
                opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
                
                # –ü—Ä–æ–±—É–µ–º 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–≤–º–µ—Å—Ç–æ 6)
                attempts = [
                    ("enhanced", self.preprocess_image_enhanced(opencv_image)),
                    ("simple", self.preprocess_image_simple(opencv_image)),
                    ("original", opencv_image)
                ]
                
                page_texts = []
                successful_attempts = []
                
                for attempt_name, processed_image in attempts:
                    try:
                        # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω OCR –≤—ã–∑–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ (–Ω–µ 2)
                        result = self.reader.readtext(processed_image, detail=0, paragraph=False)
                        text = " ".join(result)
                        
                        if text.strip():  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –Ω–µ –ø—É—Å—Ç–æ–π
                            page_texts.append(text)
                            successful_attempts.append(attempt_name)
                        
                    except Exception as e:
                        continue
                
                # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–æ–±—ã—á–Ω–æ –ª—É—á—à–∏–π)
                if page_texts:
                    best_text = max(page_texts, key=len)
                    best_idx = page_texts.index(best_text)
                    best_method = successful_attempts[best_idx]
                    
                    all_text += best_text + " "
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫–æ–π –º–µ—Ç–æ–¥ —Å—Ä–∞–±–æ—Ç–∞–ª –ª—É—á—à–µ
                    if len(page_texts) > 1:
                        print(f"    üîß –õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_method} ({len(best_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            
            ocr_time = time.time() - ocr_start
            total_time = time.time() - start_time
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.timing_stats.append({
                'file': pdf_path.name,
                'pdf_convert': pdf_time,
                'ocr_time': ocr_time,
                'total_time': total_time,
                'text_length': len(all_text)
            })
            
            return all_text
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pdf_path}: {e}")
            return ""
    
    def extract_fio(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            cleaned_text = re.sub(r'[^\w\s–∞-—è—ë–ê-–Ø–Å]', ' ', text)
            cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
            
            # –ù–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –§–ò–û
            patterns = [
                r"–ù–∞—Å—Ç–æ—è—â–µ–µ —É–¥–æ—Å—Ç–æ–≤–µ—Ä–µ–Ω–∏–µ –≤—ã–¥–∞–Ω–æ\s+(.*?)\s+–≤\s+—Ç–æ–º",
                r"—É–¥–æ—Å—Ç–æ–≤–µ—Ä–µ–Ω–∏–µ –≤—ã–¥–∞–Ω–æ\s+(.*?)\s+–≤\s+—Ç–æ–º",
                r"–≤—ã–¥–∞–Ω–æ\s+(.*?)\s+–≤\s+—Ç–æ–º\s+—á—Ç–æ",
                r"–≤—ã–¥–∞–Ω–æ\s+([–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+)",
            ]
            
            for pattern in patterns:
                match = re.search(pattern, cleaned_text, re.IGNORECASE | re.DOTALL)
                if match:
                    fio_raw = match.group(1).strip()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –§–ò–û (3 —Å–ª–æ–≤–∞, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π)
                    if self.validate_fio(fio_raw):
                        fio_clean = self.normalize_fio(fio_raw)
                        return fio_clean
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º —Ä—É—Å—Å–∫–∏—Ö –∏–º–µ–Ω
            fio_pattern = r'([–ê-–Ø–Å][–∞-—è—ë]+(?:–æ–π|–µ–π|–æ–º—É|–µ–º—É|–Ω–æ–π|–Ω–æ–º—É|—Å–∫–æ–π|—Å–∫–∏–π)\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:–µ|—É|—å)?\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:–∏—á—É|–æ–≤–∏—á—É|–µ–≤–∏—á—É|–∏—á–µ–º|–æ–≤–∏—á–µ–º|–µ–≤–∏—á–µ–º|–æ–≤–Ω–µ|–µ–≤–Ω–µ|–∏—á–Ω–µ))'
            match = re.search(fio_pattern, text)
            if match:
                fio_raw = match.group(1).strip()
                if self.validate_fio(fio_raw):
                    return self.normalize_fio(fio_raw)
            
            return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –§–ò–û: {e}")
            return None
    
    def validate_fio(self, fio):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂ –ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –§–ò–û"""
        words = fio.split()
        if len(words) < 2 or len(words) > 4:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Å–ª–æ–≤–∞ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
        for word in words:
            if not word or not word[0].isupper() or len(word) < 2:
                return False
        
        return True
    
    def normalize_fio(self, fio_raw):
        """–û—á–∏—â–∞–µ—Ç –§–ò–û (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞–¥–µ–∂–∞)"""
        fio = fio_raw.strip()
        
        # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        words = fio.split()
        normalized_words = []
        
        for word in words:
            if word:
                # –ü–µ—Ä–≤–∞—è –±—É–∫–≤–∞ –∑–∞–≥–ª–∞–≤–Ω–∞—è, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ—á–Ω—ã–µ
                normalized_word = word[0].upper() + word[1:].lower()
                normalized_words.append(normalized_word)
        
        result = ' '.join(normalized_words)
        return result
    
    def extract_program_name(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –º—É—Å–æ—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            cleaned_text = re.sub(r'[^\w\s–∞-—è—ë–ê-–Ø–Å\-\(\)\.\,\:\"¬´¬ª]', ' ', text)
            cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
            
            # –ù–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã
            patterns = [
                r'–ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ\s*["\u201C¬´]?\s*(.*?)\s*["\u201D¬ª]?\s*–≤\s*–æ–±—ä–µ–º–µ',
                r'–ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ\s*["\u201C¬´]?\s*(.*?)\s*["\u201D¬ª]?\s*\d+\s*—á–∞—Å',
                r'–ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ\s*["\u201C¬´]?\s*(.*?)\s*["\u201D¬ª]?\s*‚Ññ',
                r'–ø—Ä–æ–≥—Ä–∞–º–º–µ\s*["\u201C¬´]?\s*(.*?)\s*["\u201D¬ª]?\s*–≤\s*–æ–±—ä[–µ—ë]–º–µ',
                r'–ø—Ä–æ–≥—Ä–∞–º–º–µ\s*["\u201C¬´]?\s*(.*?)\s*["\u201D¬ª]?\s*\d+\s*—á–∞—Å',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, cleaned_text, re.IGNORECASE | re.DOTALL)
                if match:
                    program_name = match.group(1).strip()
                    
                    # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç –º—É—Å–æ—Ä–∞
                    program_name = self.clean_program_name(program_name)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏ —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å
                    if len(program_name) > 10 and self.validate_program_name(program_name):
                        return program_name
            
            # –ü–æ–∏—Å–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ–≥—Ä–∞–º–º –±–µ–∑ —É—á–µ—Ç–∞ "–ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ"
            standard_programs = [
                r'(–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω[—ã—ã–µ]+\s+–∏\s+–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω[—ã—ã–µ]+\s+–∑–∞–∫—É–ø–∫–∏.*?(?:—Ç–µ–æ—Ä–∏—è\s+–∏\s+–ø—Ä–∞–∫—Ç–∏–∫–∞|–ø—Ä–∞–∫—Ç–∏–∫–∞))',
                r'([–û–æ0]\s*–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω–æ–π\s+—Å–∏—Å—Ç–µ–º–µ\s+–≤\s+—Å—Ñ–µ—Ä–µ\s+–∑–∞–∫—É–ø–æ–∫)',
                r'(44.*?–§–ó.*?–∑–∞–∫—É–ø)',
                r'(–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω[–æ–∞—è]+\s+—Å–∏—Å—Ç–µ–º[–∞–µ]\s+–≤\s+—Å—Ñ–µ—Ä–µ\s+–∑–∞–∫—É–ø–æ–∫)',
            ]
            
            for pattern in standard_programs:
                match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                if match:
                    program_name = self.clean_program_name(match.group(1))
                    if len(program_name) > 10:
                        return program_name
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –∏—Å–∫–∞–∂–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            fallback_patterns = [
                r'(–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω[–∞-—è—à—ã–µ]*\s+–∏\s+–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω[–∞-—è—à—ã–µ]*\s+–∑–∞–∫—É–ø–∫–∏[^"]*(?:—Ç–µ–æ—Ä–∏—è|–ø—Ä–∞–∫—Ç–∏–∫–∞)?)',
                r'([–û–æ0]\s*–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω[–∞-—è]*\s+—Å–∏—Å—Ç–µ–º[–∞-—è]*\s+–≤\s+—Å—Ñ–µ—Ä–µ\s+–∑–∞–∫—É–ø–æ–∫[–∞-—è]*)',
                r'(–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤[–∞-—è—à—ã–µ]*\s+[–∏—è]*\s*–º—É–Ω–∏—Ü–∏[–∞-—è—à—ã–µ]*\s+–∑–∞–∫—É–ø[–∞-—è–∫–∏]*)',
                r'(44[^"]*–§–ó[^"]*–∑–∞–∫—É–ø[–∞-—è–∫–∏]*)',
            ]
            
            for pattern in fallback_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    program_name = self.clean_program_name(match.group(1))
                    if len(program_name) > 15:
                        return program_name
            
            return None
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã: {e}")
            return None
    
    def clean_program_name(self, name):
        """–û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        if not name:
            return ""
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        name = re.sub(r'["\u201C\u201D¬´¬ª()"]', '', name)
        name = re.sub(r'\s+', ' ', name)
        name = name.strip()
        
        # –£–±–∏—Ä–∞–µ–º –º—É—Å–æ—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ –∏ –Ω–∞—á–∞–ª–µ
        name = re.sub(r'^[^\w]*', '', name)
        name = re.sub(r'[\*\#\{\}\[\]\$\%\@\!\+\=\<\>]+.*$', '', name)
        
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã (–±–æ–ª–µ–µ 3 –ø–æ–¥—Ä—è–¥)
        name = re.sub(r'(.)\1{3,}', r'\1', name)
        
        # –£–±–∏—Ä–∞–µ–º —Ñ—Ä–∞–∑—ã "–≤ –æ–±—ä—ë–º–µ", "–≤ –æ–±—ä–µ–º–µ" –∏ —Ü–∏—Ñ—Ä—ã –ø–æ—Å–ª–µ –Ω–∏—Ö
        name = re.sub(r'\s*[–≤–í]\s*–æ–±—ä[–µ—ë]–º–µ.*$', '', name)
        name = re.sub(r'\s*[–≤–í]\s*–æ–±—å[–µ—ë]–º–µ.*$', '', name)
        name = re.sub(r'\s*–æ–±—ä[–µ—ë]–º—Å.*$', '', name)
        name = re.sub(r'\s*–æ–±—ä[–µ—ë]–Ω–µ.*$', '', name)
        name = re.sub(r'\s*–æ—å[–µ—ë]–º–µ.*$', '', name)
        name = re.sub(r'\s*\d+\s*—á–∞—Å.*$', '', name)
        name = re.sub(r'\s*\d+\s*‚ÇΩ.*$', '', name)
        
        # –ó–∞–º–µ–Ω—è–µ–º –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        replacements = [
            ('0', '–û'),
            ('–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω[–∞-—è—à—ã]*', '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ'),
            ('–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤[–∞-—è—à—ã]*', '–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ'),
            ('–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω[–∞-—è—à—ã]*', '–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω—ã–µ'),
            ('–º—É–Ω–∏—Ü–∏[–∞-—è—à—ã]*', '–º—É–Ω–∏—Ü–∏–ø–∞–ª—å–Ω—ã–µ'),
            ('–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω[–∞-—è]*', '–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω–æ–π'),
            ('–∫–æ–ø—Ç—Ä–∞–∫—Ç–Ω[–∞-—è]*', '–∫–æ–Ω—Ç—Ä–∞–∫—Ç–Ω–æ–π'),
            ('—Å–∏—Å—Ç–µ–º[–∞-—è]*', '—Å–∏—Å—Ç–µ–º–µ'),
            ('–∑–∞–∫—É–ø–æ–∫[—ä—ç]', '–∑–∞–∫—É–ø–æ–∫'),
            ('–∑–∞–∫—É–ø[–∞-—è–∫–∏]*', '–∑–∞–∫—É–ø–∫–∏'),
            ('44[^"]*–§–ó', '44-–§–ó'),
        ]
        
        for pattern, replacement in replacements:
            name = re.sub(pattern, replacement, name, flags=re.IGNORECASE)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        name = re.sub(r'\s+', ' ', name)
        
        return name.strip()
    
    def validate_program_name(self, name):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
        letters = len(re.findall(r'[–∞-—è—ë–ê-–Ø–Å]', name))
        total = len(name)
        
        if total == 0:
            return False
        
        return (letters / total) > 0.7
    
    def extract_certificate_number(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞"""
        try:
            patterns = [
                r'(\d{2}\s*[–ê-–Ø–Å]{2,5}\d?\s*\d{6})',
                r'(\d{2}\s+[–ê-–Ø–Å]+\s*\d+)',
                r'([–ê-–Ø–Å]{2,5}\s*\d{6,8})',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text)
                if matches:
                    return matches[0].strip()
                
            return None
        except Exception as e:
            return None
    
    def extract_date(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É"""
        try:
            pattern = r'(\d{1,2}\.\d{1,2}\.\d{4})'
            matches = re.findall(pattern, text)
            
            if matches:
                return matches[-1]
            
            return None
        except Exception as e:
            return None
    
    def extract_hours(self, text):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤"""
        try:
            patterns = [
                r'–≤\s*–æ–±—ä[–µ—ë]–º–µ\s*(\d+)\s*—á–∞—Å',
                r'–í—Å–µ–≥–æ\s*(\d+)',
                r'(\d+)\s*—á–∞—Å[–∞–æ–≤]?(?:\s|$)',
                r'–æ–±—ä—ë–º—Å\s*(\d+)',
                r'–æ–±—ä—ë–Ω–µ\s*(\d+)',
            ]
            
            found_hours = []
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                for match in matches:
                    hours = int(match)
                    if 8 <= hours <= 1000:
                        found_hours.append(hours)
            
            if found_hours:
                hour_counts = Counter(found_hours)
                most_common_hours = hour_counts.most_common(1)[0][0]
                return str(most_common_hours)
            
            return None
        except Exception as e:
            return None
    
    def sanitize_filename(self, filename):
        """–û—á–∏—â–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –æ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'\s+', ' ', filename)
        if len(filename) > 100:
            filename = filename[:100]
        return filename.strip()
    
    def process_single_pdf(self, pdf_path, file_number, total_files):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω PDF —Ñ–∞–π–ª"""
        print(f"\nüìÑ –§–∞–π–ª {file_number}/{total_files}: {pdf_path.name}")
        
        file_start_time = time.time()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º
        text = self.extract_text_from_pdf_balanced(pdf_path)
        
        if not text:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
            return False
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –æ—Ç–ª–∞–¥–∫–∏ —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        debug_text_file = self.debug_dir / f"{pdf_path.stem}_ocr_text.txt"
        with open(debug_text_file, 'w', encoding='utf-8') as f:
            f.write(text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        fio = self.extract_fio(text)
        program_name = self.extract_program_name(text)
        cert_number = self.extract_certificate_number(text)
        cert_date = self.extract_date(text)
        hours = self.extract_hours(text)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
        file_time = time.time() - file_start_time
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {file_time:.1f}—Å | –¢–µ–∫—Å—Ç: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print(f"üë§ –§–ò–û: {fio[:30] + '...' if fio and len(fio) > 30 else fio or '–ù–ï –ù–ê–ô–î–ï–ù–û'}")
        print(f"üéì –ü—Ä–æ–≥—Ä–∞–º–º–∞: {program_name[:40] + '...' if program_name and len(program_name) > 40 else program_name or '–ù–ï –ù–ê–ô–î–ï–ù–û'}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        if not fio or not program_name:
            print(f"‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—É–¥–∞—á–Ω–∞")
            shutil.copy2(pdf_path, self.unknown_dir / pdf_path.name)
            
            self.csv_data.append({
                '–§–ò–û': fio or '–ù–ï –ù–ê–ô–î–ï–ù–û',
                '–ù–∞–∑–≤–∞–Ω–∏–µ': program_name or '–ù–ï –ù–ê–ô–î–ï–ù–û',
                '–ù–æ–º–µ—Ä': cert_number or '',
                '–î–∞—Ç–∞': cert_date or '',
                '–ß–∞—Å—ã': hours or '',
                '–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É': str(self.unknown_dir / pdf_path.name)
            })
            return False
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
        safe_program_name = self.sanitize_filename(program_name)
        program_dir = self.certificates_dir / safe_program_name
        program_dir.mkdir(exist_ok=True)
        
        safe_fio = self.sanitize_filename(fio)
        new_filename = f"{safe_fio}.pdf"
        new_path = program_dir / new_filename
        
        counter = 1
        while new_path.exists():
            new_filename = f"{safe_fio}_{counter}.pdf"
            new_path = program_dir / new_filename
            counter += 1
        
        shutil.copy2(pdf_path, new_path)
        
        self.csv_data.append({
            '–§–ò–û': fio,
            '–ù–∞–∑–≤–∞–Ω–∏–µ': program_name,
            '–ù–æ–º–µ—Ä': cert_number or '',
            '–î–∞—Ç–∞': cert_date or '',
            '–ß–∞—Å—ã': hours or '',
            '–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É': str(new_path)
        })
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
        return True
    
    def show_timing_stats(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏"""
        if not self.timing_stats:
            return
            
        df = pd.DataFrame(self.timing_stats)
        
        avg_pdf = df['pdf_convert'].mean()
        avg_ocr = df['ocr_time'].mean()
        avg_total = df['total_time'].mean()
        avg_text_len = df['text_length'].mean()
        
        print(f"\n‚è±Ô∏è  –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–†–ï–ú–ï–ù–ò:")
        print(f"   PDF –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è: {avg_pdf:.1f} —Å–µ–∫/—Ñ–∞–π–ª")
        print(f"   OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞: {avg_ocr:.1f} —Å–µ–∫/—Ñ–∞–π–ª") 
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {avg_total:.1f} —Å–µ–∫/—Ñ–∞–π–ª")
        print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {avg_text_len:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ù–∞–π—Ç–∏ —Å–∞–º—ã–π –º–µ–¥–ª–µ–Ω–Ω—ã–π –∏ –±—ã—Å—Ç—Ä—ã–π —Ñ–∞–π–ª—ã
        slowest = df.loc[df['total_time'].idxmax()]
        fastest = df.loc[df['total_time'].idxmin()]
        print(f"   –°–∞–º—ã–π –º–µ–¥–ª–µ–Ω–Ω—ã–π: {slowest['file']} ({slowest['total_time']:.1f} —Å–µ–∫)")
        print(f"   –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π: {fastest['file']} ({fastest['total_time']:.1f} —Å–µ–∫)")
    
    def process_all_pdfs(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input"""
        if not self.input_dir.exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ {self.input_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            return
        
        pdf_files = list(self.input_dir.glob("*.pdf"))
        if not pdf_files:
            print("‚ùå PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ input!")
            return
        
        print(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤")
        print("="*60)
        
        start_time = time.time()
        successful = 0
        
        for i, pdf_file in enumerate(pdf_files, 1):
            if self.process_single_pdf(pdf_file, i, len(pdf_files)):
                successful += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ñ–∞–π–ª–æ–≤
            if i % 10 == 0:
                elapsed = time.time() - start_time
                avg_time = elapsed / i
                estimated_total = avg_time * len(pdf_files)
                remaining = estimated_total - elapsed
                
                print(f"\nüìä –ü–†–û–ì–†–ï–°–°: {i}/{len(pdf_files)} —Ñ–∞–π–ª–æ–≤")
                print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}/{i} ({successful/i*100:.1f}%)")
                print(f"   ‚è±Ô∏è  –ü—Ä–æ—à–ª–æ: {elapsed/60:.1f} –º–∏–Ω")
                print(f"   üîÆ –û—Å—Ç–∞–ª–æ—Å—å: {remaining/60:.1f} –º–∏–Ω")
                print(f"   ‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {avg_time:.1f} —Å–µ–∫/—Ñ–∞–π–ª")
        
        total_time = time.time() - start_time
        
        print(f"\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful} –∏–∑ {len(pdf_files)} —Ñ–∞–π–ª–æ–≤ ({successful/len(pdf_files)*100:.1f}%)")
        print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time/60:.1f} –º–∏–Ω—É—Ç")
        print(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {total_time/len(pdf_files):.1f} —Å–µ–∫/—Ñ–∞–π–ª")
        
        if successful < len(pdf_files):
            print(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(pdf_files) - successful}")
            print(f"üìÅ –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ: –ù–µ–æ–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Ä–µ–º–µ–Ω–∏
        self.show_timing_stats()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV
        self.save_csv()
    
    def save_csv(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ CSV —Ñ–∞–π–ª"""
        if not self.csv_data:
            print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV")
            return
        
        df = pd.DataFrame(self.csv_data)
        csv_path = self.debug_dir / "table.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {csv_path}")

def main():
    
    processor = CertificateProcessorBalanced()
    processor.process_all_pdfs()

if __name__ == "__main__":
    main()